{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input some Chinese text:\n"
     ]
    }
   ],
   "source": [
    "print(\"Input some Chinese text:\")\n",
    "text=input()\n",
    "# text='一家人在吃饭。 儿子问：“爸爸，虫子能吃吗？” 爸爸说：“儿子， 妈妈做的饭菜好吃吗？” 儿子说：“很好吃！” 爸爸说：“那么，你好好吃饭。 吃饭的时候，不要说话。好吗？” 儿子说：“好的。”'\n",
    "# text='在一个商店,他看到一只小猫,对不起,大家到了清华大学'\n",
    "# text='东南西北  生意   做生意  也称为雨滴蛋糕（英语：Raindrop Cake），来自日本北杜市，使用日本赤石山脉的水所制成[1]，只有夏季贩售。有着天然甜味，看起来像一大块无色的果冻，但制造商坚持这是糕饼。'\n",
    "# print(text)\n",
    "# ==============================\n",
    "\n",
    "# !pip install wget termcolor jieba\n",
    "import json\n",
    "import termcolor\n",
    "import jieba\n",
    "import wget\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import os.path\n",
    "# import re\n",
    "\n",
    "\n",
    "# check if the HSK files exist  \n",
    "Path(\"./assets\").mkdir(parents=True, exist_ok=True)\n",
    "if not os.path.exists('assets/hsk-level-1.json'):\n",
    "    wget.download('https://raw.githubusercontent.com/simon2016bht/TagHskWords/master/assets/hsk-level-1.json')\n",
    "    shutil.move('./hsk-level-1.json', 'assets/hsk-level-1.json')\n",
    "if not os.path.exists('assets/hsk-level-2.json'):\n",
    "    wget.download('https://raw.githubusercontent.com/simon2016bht/TagHskWords/master/assets/hsk-level-2.json')\n",
    "    shutil.move('./hsk-level-2.json', 'assets/hsk-level-2.json')\n",
    "if not os.path.exists('assets/hsk-level-3.json'):\n",
    "    wget.download('https://raw.githubusercontent.com/simon2016bht/TagHskWords/master/assets/hsk-level-3.json')\n",
    "    shutil.move('./hsk-level-3.json', 'assets/hsk-level-3.json')\n",
    "if not os.path.exists('assets/hsk-level-4.json'):\n",
    "    wget.download('https://raw.githubusercontent.com/simon2016bht/TagHskWords/master/assets/hsk-level-4.json')\n",
    "    shutil.move('./hsk-level-4.json', 'assets/hsk-level-4.json')\n",
    "if not os.path.exists('assets/hsk-level-5.json'):\n",
    "    wget.download('https://raw.githubusercontent.com/simon2016bht/TagHskWords/master/assets/hsk-level-5.json')\n",
    "    shutil.move('./hsk-level-5.json', 'assets/hsk-level-5.json')\n",
    "if not os.path.exists('assets/hsk-level-6.json'):\n",
    "    wget.download('https://raw.githubusercontent.com/simon2016bht/TagHskWords/master/assets/hsk-level-6.json')\n",
    "    shutil.move('./hsk-level-6.json', 'assets/hsk-level-6.json')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load file contents into lists\n",
    "with open('assets/hsk-level-1.json') as file:\n",
    "    hsk1_data = json.load(file)\n",
    "hsk1_words = []\n",
    "for item in hsk1_data:\n",
    "    hsk1_words.append(item['hanzi'])\n",
    "\n",
    "with open('assets/hsk-level-2.json') as file:\n",
    "    hsk2_data = json.load(file)\n",
    "hsk2_words = []\n",
    "for item in hsk2_data:\n",
    "    hsk2_words.append(item['hanzi'])\n",
    "\n",
    "with open('assets/hsk-level-3.json') as file:\n",
    "    hsk3_data = json.load(file)\n",
    "hsk3_words = []\n",
    "for item in hsk3_data:\n",
    "    hsk3_words.append(item['hanzi'])\n",
    "    \n",
    "with open('assets/hsk-level-4.json') as file:\n",
    "    hsk4_data = json.load(file)\n",
    "hsk4_words = []\n",
    "for item in hsk4_data:\n",
    "    hsk4_words.append(item['hanzi'])\n",
    "    \n",
    "with open('assets/hsk-level-5.json') as file:\n",
    "    hsk5_data = json.load(file)\n",
    "hsk5_words = []\n",
    "for item in hsk5_data:\n",
    "    hsk5_words.append(item['hanzi'])\n",
    "    \n",
    "with open('assets/hsk-level-6.json') as file:\n",
    "    hsk6_data = json.load(file)\n",
    "hsk6_words = []\n",
    "for item in hsk6_data:\n",
    "    hsk6_words.append(item['hanzi'])\n",
    "# =================================\n",
    "\n",
    "# tag words which is of HSK 1,2,3\n",
    "tagged_words_hsk1=[]\n",
    "tagged_words_hsk2=[]\n",
    "tagged_words_hsk3=[]\n",
    "tagged_words_hsk4=[]\n",
    "tagged_words_hsk5=[]\n",
    "tagged_words_hsk6=[]\n",
    "\n",
    "\n",
    "# using jieba for word segmentation\n",
    "for word in jieba.cut(text, cut_all=False):\n",
    "    #cut word in small pieces\n",
    "#     print(word,len(word))\n",
    "    # for each word output from jieba, check the subset of it\n",
    "    subset_of_word=[]\n",
    "    \n",
    "    if len(word) >= 5:\n",
    "#         print(word,5)\n",
    "        subset_of_word.append(word[0])\n",
    "        subset_of_word.append(word[1])\n",
    "        subset_of_word.append(word[2])\n",
    "        subset_of_word.append(word[3])\n",
    "        subset_of_word.append(word[4])\n",
    "        subset_of_word.append(word[0:2])\n",
    "        subset_of_word.append(word[1:3])\n",
    "        subset_of_word.append(word[2:4])\n",
    "        subset_of_word.append(word[3:5])\n",
    "        subset_of_word.append(word[0:3])\n",
    "        subset_of_word.append(word[1:4])\n",
    "        subset_of_word.append(word[2:5])\n",
    "        subset_of_word.append(word[0:4])\n",
    "        subset_of_word.append(word[1:5])\n",
    "\n",
    "    elif len(word) >= 4:\n",
    "#         print(word,4)\n",
    "        subset_of_word.append(word[0])\n",
    "        subset_of_word.append(word[1])\n",
    "        subset_of_word.append(word[2])\n",
    "        subset_of_word.append(word[3])\n",
    "        subset_of_word.append(word[0:2])\n",
    "        subset_of_word.append(word[1:3])\n",
    "        subset_of_word.append(word[2:4])\n",
    "        subset_of_word.append(word[0:3])\n",
    "        subset_of_word.append(word[1:4])\n",
    "    elif len(word) >= 3:\n",
    "#         print(word,3)\n",
    "        subset_of_word.append(word[0])\n",
    "        subset_of_word.append(word[1])\n",
    "        subset_of_word.append(word[2])\n",
    "        subset_of_word.append(word[0:2])\n",
    "        subset_of_word.append(word[1:3])\n",
    "    elif len(word)>=2:\n",
    "#         print(word,2)\n",
    "        subset_of_word.append(word[0])\n",
    "        subset_of_word.append(word[1])\n",
    "\n",
    "# check the word directly from jieba    \n",
    "    if word in hsk1_words and word not in tagged_words_hsk1:\n",
    "        tagged_words_hsk1.append(word)\n",
    "    elif word in hsk2_words and word not in tagged_words_hsk2:\n",
    "        tagged_words_hsk2.append(word)\n",
    "    elif word in hsk3_words and word not in tagged_words_hsk3:\n",
    "        tagged_words_hsk3.append(word)\n",
    "    elif word in hsk4_words and word not in tagged_words_hsk4:\n",
    "        tagged_words_hsk4.append(word)\n",
    "    elif word in hsk5_words and word not in tagged_words_hsk5:\n",
    "        tagged_words_hsk5.append(word)\n",
    "    elif word in hsk6_words and word not in tagged_words_hsk6:\n",
    "        tagged_words_hsk6.append(word)\n",
    "    \n",
    "    \n",
    "# also check subset of the word \n",
    "    for i in subset_of_word:\n",
    "#         print(i)\n",
    "        if i in hsk1_words and i not in tagged_words_hsk1:\n",
    "            tagged_words_hsk1.append(i)\n",
    "        if i in hsk2_words and i not in tagged_words_hsk2:\n",
    "            tagged_words_hsk2.append(i)\n",
    "        if i in hsk3_words and i not in tagged_words_hsk3:\n",
    "            tagged_words_hsk3.append(i)\n",
    "        if i in hsk4_words and i not in tagged_words_hsk4:\n",
    "            tagged_words_hsk4.append(i)\n",
    "        if i in hsk5_words and i not in tagged_words_hsk5:\n",
    "            tagged_words_hsk5.append(i)\n",
    "        if i in hsk6_words and i not in tagged_words_hsk6:\n",
    "            tagged_words_hsk6.append(i)\n",
    "# print(\"=======================\")\n",
    "# print(\"HSK1:\",tagged_words_hsk1)\n",
    "# print(\"HSK2:\",tagged_words_hsk2)\n",
    "# print(\"HSK3:\",tagged_words_hsk3)\n",
    "\n",
    "# ====================================\n",
    "\n",
    "\n",
    "# Create list of flags for each HSK level\n",
    "\n",
    "# initialize flag as list of 0\n",
    "hsk1_flag=[0]*len(text)\n",
    "hsk2_flag=[0]*len(text)\n",
    "hsk3_flag=[0]*len(text)\n",
    "hsk4_flag=[0]*len(text)\n",
    "hsk5_flag=[0]*len(text)\n",
    "hsk6_flag=[0]*len(text)\n",
    "\n",
    "\n",
    "\n",
    "## flag a slice of list according to the length of the HSK word; argument \"hsk_level\" is redundant but workable for next step when combining flags\n",
    "def tag(flag_list_name,starting_position, length, hsk_level):\n",
    "    for i in range(length):\n",
    "        flag_list_name[starting_position+i]=hsk_level\n",
    "        None\n",
    "\n",
    "# going through the text\n",
    "for cursor_position in enumerate(text):\n",
    "    # test word from one syllable to 4 syllables, flag of longer word will override short word in the same level\n",
    "    window=text[cursor_position[0]:cursor_position[0]+4]\n",
    "    # check if the word size is as expected; avoid out of range problems at the end of the text\n",
    "    if len(window) != 4:\n",
    "        None\n",
    "    elif window in tagged_words_hsk1:\n",
    "        tag(hsk1_flag,cursor_position[0],4,1)\n",
    "    elif window in tagged_words_hsk2:\n",
    "        tag(hsk2_flag,cursor_position[0],4,2)\n",
    "    elif window in tagged_words_hsk3:\n",
    "        tag(hsk3_flag,cursor_position[0],4,3)\n",
    "    elif window in tagged_words_hsk4:\n",
    "        tag(hsk4_flag,cursor_position[0],4,4)\n",
    "    elif window in tagged_words_hsk5:\n",
    "        tag(hsk5_flag,cursor_position[0],4,5)\n",
    "    elif window in tagged_words_hsk6:\n",
    "        tag(hsk6_flag,cursor_position[0],4,6)\n",
    "        \n",
    "    window=text[cursor_position[0]:cursor_position[0]+3]        \n",
    "    if len(window) != 3:\n",
    "        None    \n",
    "    elif window in tagged_words_hsk1:\n",
    "#         print(window) \n",
    "        tag(hsk1_flag,cursor_position[0],3,1)\n",
    "    elif window in tagged_words_hsk2:\n",
    "        tag(hsk2_flag,cursor_position[0],3,2)\n",
    "    elif window in tagged_words_hsk3:\n",
    "        tag(hsk3_flag,cursor_position[0],3,3)\n",
    "    elif window in tagged_words_hsk4:\n",
    "        tag(hsk4_flag,cursor_position[0],3,4)\n",
    "    elif window in tagged_words_hsk5:\n",
    "        tag(hsk5_flag,cursor_position[0],3,5)\n",
    "    elif window in tagged_words_hsk6:\n",
    "        tag(hsk6_flag,cursor_position[0],3,6)\n",
    "\n",
    "    window=text[cursor_position[0]:cursor_position[0]+2]\n",
    "    if len(window) != 2:\n",
    "        None\n",
    "    elif window in tagged_words_hsk1:\n",
    "#         print(window) \n",
    "        tag(hsk1_flag,cursor_position[0],2,1)\n",
    "    elif window in tagged_words_hsk2:\n",
    "        tag(hsk2_flag,cursor_position[0],2,2)\n",
    "    elif window in tagged_words_hsk3:\n",
    "        tag(hsk3_flag,cursor_position[0],2,3)\n",
    "    elif window in tagged_words_hsk4:\n",
    "        tag(hsk4_flag,cursor_position[0],2,4)\n",
    "    elif window in tagged_words_hsk5:\n",
    "        tag(hsk5_flag,cursor_position[0],2,5)\n",
    "    elif window in tagged_words_hsk6:\n",
    "        tag(hsk6_flag,cursor_position[0],2,6)\n",
    "\n",
    "    window=text[cursor_position[0]:cursor_position[0]+1]    \n",
    "    if window in tagged_words_hsk1:\n",
    "        tag(hsk1_flag,cursor_position[0],1,1)\n",
    "    elif window in tagged_words_hsk2:\n",
    "        tag(hsk2_flag,cursor_position[0],1,2)\n",
    "    elif window in tagged_words_hsk3:\n",
    "        tag(hsk3_flag,cursor_position[0],1,3)\n",
    "    elif window in tagged_words_hsk4:\n",
    "        tag(hsk4_flag,cursor_position[0],1,4)\n",
    "    elif window in tagged_words_hsk5:\n",
    "        tag(hsk5_flag,cursor_position[0],1,5)\n",
    "    elif window in tagged_words_hsk6:\n",
    "        tag(hsk6_flag,cursor_position[0],1,6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### check tagging result for each HSK level\n",
    "# for i in enumerate(text):\n",
    "#     print(i[0],text[i[0]],hsk1_flag[i[0]], hsk2_flag[i[0]], hsk3_flag[i[0]], hsk4_flag[i[0]], hsk5_flag[i[0]], hsk6_flag[i[0]])\n",
    "\n",
    "\n",
    "# ======================================\n",
    "            \n",
    "## combine flags (a list of dictionary) and assign font color and background color to each character\n",
    "# Available text colors: red, green, yellow, blue, magenta, cyan, white.\n",
    "\n",
    "HSK1_color = 'green'\n",
    "HSK2_color = 'green'\n",
    "HSK3_color = 'green'\n",
    "HSK123_color = 'green'\n",
    "HSK4_color = 'blue'\n",
    "HSK5_color = 'red'\n",
    "HSK6_color = 'yellow'\n",
    "\n",
    "\n",
    "combined_flag = []\n",
    "for i in enumerate(text):\n",
    "    d = {'character':text[i[0]],'font_color':None, 'bg_color':None}\n",
    "    combined_flag.append(d)\n",
    "\n",
    "for (cursor_position,character) in enumerate(text):\n",
    "#     print(cursor_position, character,hsk1_flag[cursor_position])\n",
    "    if hsk1_flag[cursor_position] != 0:\n",
    "        combined_flag[cursor_position]['font_color'] = HSK123_color\n",
    "    if hsk2_flag[cursor_position] != 0:\n",
    "        combined_flag[cursor_position]['font_color'] = HSK123_color\n",
    "    if hsk3_flag[cursor_position] != 0:\n",
    "        combined_flag[cursor_position]['font_color'] = HSK123_color\n",
    "    if hsk4_flag[cursor_position] != 0:\n",
    "        combined_flag[cursor_position]['font_color'] = HSK4_color\n",
    "    \n",
    "    # for higher HSK level word, first check if it is already tagged. If so, using background color.\n",
    "#     if hsk4_flag[cursor_position] != 0:\n",
    "#         if combined_flag[cursor_position]['font_color'] == None:\n",
    "#             combined_flag[cursor_position]['font_color'] = HSK4_color\n",
    "#         elif combined_flag[cursor_position]['bg_color'] == None:\n",
    "#             combined_flag[cursor_position]['bg_color'] = 'on_' + HSK4_color\n",
    "    \n",
    "    if hsk5_flag[cursor_position] != 0:\n",
    "        if combined_flag[cursor_position]['font_color'] == None:\n",
    "            combined_flag[cursor_position]['font_color'] = HSK5_color\n",
    "        elif combined_flag[cursor_position]['bg_color'] == None:\n",
    "            combined_flag[cursor_position]['bg_color'] = 'on_' + HSK5_color\n",
    "            \n",
    "\n",
    "    if hsk6_flag[cursor_position] != 0:\n",
    "        if combined_flag[cursor_position]['font_color'] == None:\n",
    "            combined_flag[cursor_position]['font_color'] = HSK6_color\n",
    "        elif combined_flag[cursor_position]['bg_color'] == None:\n",
    "            combined_flag[cursor_position]['bg_color'] = 'on_' + HSK6_color\n",
    "    \n",
    "# =======================================\n",
    "\n",
    "\n",
    "# output text according to the combined flag\n",
    "print(\"Colored text (green for HSK1234, red for HSK5, yellow for HSK6):\\n---\")\n",
    "for i in enumerate(text):\n",
    "    colored_word = termcolor.colored(i[1], color=combined_flag[i[0]]['font_color'], on_color=combined_flag[i[0]]['bg_color'])\n",
    "    # change red color in background to a bright color 256 bit\n",
    "    colored_word =  colored_word.replace('\\x1b[41m', '\\x1b[48;5;211m')\n",
    "    print(colored_word, end=\"\")\n",
    "print(\"\\n---\")\n",
    "print('HSK3 words:', tagged_words_hsk3)\n",
    "print('HSK4 words:', tagged_words_hsk4)\n",
    "print(\"---\\n\")\n",
    "print('HSK5 words:', tagged_words_hsk5)\n",
    "print('HSK6 words:', tagged_words_hsk6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;211mtest\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "# Python program to print \n",
    "# colored text and background \n",
    "def prRed(skk): print(\"\\033[91m {}\\033[00m\" .format(skk)) \n",
    "def prGreen(skk): print(\"\\033[92m {}\\033[00m\" .format(skk)) \n",
    "def prYellow(skk): print(\"\\033[93m {}\\033[00m\" .format(skk)) \n",
    "def prLightPurple(skk): print(\"\\033[94m {}\\033[00m\" .format(skk)) \n",
    "def prPurple(skk): print(\"\\033[95m {}\\033[00m\" .format(skk)) \n",
    "def prCyan(skk): print(\"\\033[96m {}\\033[00m\" .format(skk)) \n",
    "def prLightGray(skk): print(\"\\033[97m {}\\033[00m\" .format(skk)) \n",
    "def prBlack(skk): print(\"\\033[98m {}\\033[00m\" .format(skk)) \n",
    "\n",
    "# prCyan(\"Hello World, \") \n",
    "# prYellow(\"It's\") \n",
    "# prGreen(\"Geeks\") \n",
    "# prRed(\"For\") \n",
    "# prGreen(\"Geeks\") \n",
    "# print(\"\\033[38;5;2;48;5;1mtest\")\n",
    "# print(\"\\033[38;5;2;48;5;9mtest\")\n",
    "print(\"\\033[48;5;211m\",\"test\",\"\\033[00m\",sep='')\n",
    "# print(\"\\033[38;5;2;48;5;212mtest\")\n",
    "# print(\"\\033[38;5;2;48;5;213mtest\")\n",
    "\n",
    "# print(\"\\033[38;5;2;48;5;204mtest\")\n",
    "# print(\"\\033[38;5;2;48;5;198mtest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x1b[31m佣\\x1b[0m'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colored_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41m\u001b[32m系\u001b[0m\n",
      "\u001b[48;5;211m\u001b[32m系\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('\\x1b[41m\\x1b[32m系\\x1b[0m')\n",
    "\n",
    "print('\\033[48;5;211m\\x1b[32m系\\x1b[0m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;211m\u001b[32m系\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "colored_word =  colored_word.replace('\\x1b[41m', '\\033[48;5;211m')\n",
    "print(colored_word)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
